{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you approach resolving a complex ethical dilemma involving autonomous AI systems prioritizing the greater good, while also considering individual rights and the potential for unintended consequences?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Resolving a complex ethical dilemma involving autonomous AI systems requires a structured approach that examines the nuances of ethical theories, stakeholder perspectives, and potential outcomes. Here's a step-by-step framework that can guide this process:\n",
       "\n",
       "### 1. Define the Ethical Dilemma\n",
       "Clearly articulate the specifics of the dilemma. Identify the competing values at play, such as the greater good versus individual rights, and outline the context in which the autonomous AI will operate.\n",
       "\n",
       "### 2. Identify Stakeholders\n",
       "Determine who is affected by the decision. This includes not only the users of the AI system but also individuals whose rights may be impacted, communities, and broader society. Understanding their perspectives is crucial.\n",
       "\n",
       "### 3. Gather Relevant Data\n",
       "Collect data on the implications of the AI's decisions. This includes empirical evidence about potential outcomes, historical precedents, and expert opinions. Understanding the technology's capabilities and limitations can also help inform the decision.\n",
       "\n",
       "### 4. Consider Ethical Frameworks\n",
       "Analyze the dilemma through different ethical lenses:\n",
       "- **Utilitarianism**: Evaluate how decisions affect the overall good and weigh the benefits against the harms.\n",
       "- **Deontological Ethics**: Consider duties and rights, emphasizing individual rights regardless of the outcomes.\n",
       "- **Virtue Ethics**: Reflect on the character and values that should guide decisions about the AI's actions.\n",
       "\n",
       "### 5. Assess the Potential for Unintended Consequences\n",
       "Conduct a thorough risk assessment to understand potential unintended consequences of the AI's actions. This involves scenario planning to consider various outcomes and their likelihood.\n",
       "\n",
       "### 6. Develop Guiding Principles\n",
       "Establish a set of ethical principles that will guide the design and deployment of the AI system. These principles should reflect a balance between the greater good and individual rights, transparency, accountability, and fairness.\n",
       "\n",
       "### 7. Create Feedback Mechanisms\n",
       "Implement systems for ongoing monitoring and evaluation of the AI's impact. This involves creating feedback loops with stakeholders to adapt and improve the system based on real-world outcomes.\n",
       "\n",
       "### 8. Engage Stakeholders in Dialogue\n",
       "Facilitate discussions with stakeholders to gather insights, address concerns, and refine the approach. This can help build trust and ensure that diverse perspectives inform the decision-making process.\n",
       "\n",
       "### 9. Explore Compromise Solutions\n",
       "Look for options that may satisfy both the prioritization of the greater good and the protection of individual rights. This could include limited opt-outs for individuals, layered decision-making processes, or tiered approaches based on risk assessment.\n",
       "\n",
       "### 10. Implement and Review\n",
       "After determining a course of action, implement it with transparency and accountability. Establish a clear review process to examine the outcomes and make necessary adjustments based on findings and stakeholder feedback.\n",
       "\n",
       "### 11. Stay Informed\n",
       "Stay abreast of developments in ethical standards, regulatory frameworks, and societal attitudes toward AI and its implications. Continuous education and adaptation are critical as technology evolves.\n",
       "\n",
       "### Conclusion\n",
       "Resolving ethical dilemmas in autonomous AI requires careful consideration of competing interests, ongoing stakeholder engagement, and a commitment to transparency and accountability. By following a structured approach, we can better navigate the complexities of these dilemmas while striving for equitable outcomes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mclaude-3-7-sonnet-latest\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m claude = Anthropic()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response = \u001b[43mclaude\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m answer = response.content[\u001b[32m0\u001b[39m].text\n\u001b[32m      9\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents/.venv/lib/python3.12/site-packages/anthropic/_utils/_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents/.venv/lib/python3.12/site-packages/anthropic/resources/messages/messages.py:954\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    948\u001b[39m     warnings.warn(\n\u001b[32m    949\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    950\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    951\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    952\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1290\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1276\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1277\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1278\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1285\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1286\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1287\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1288\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1289\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1290\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1009\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1006\u001b[39m options = \u001b[38;5;28mself\u001b[39m._prepare_options(options)\n\u001b[32m   1008\u001b[39m remaining_retries = max_retries - retries_taken\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n\u001b[32m   1012\u001b[39m kwargs: HttpxSendArgs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:505\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected JSON data type, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(json_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, cannot merge with `extra_body`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m headers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m params = _merge_mappings(\u001b[38;5;28mself\u001b[39m.default_query, options.params)\n\u001b[32m    507\u001b[39m content_type = headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:446\u001b[39m, in \u001b[36mBaseClient._build_headers\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    436\u001b[39m custom_headers = options.headers \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    437\u001b[39m headers_dict = _merge_mappings(\n\u001b[32m    438\u001b[39m     {\n\u001b[32m    439\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx-stainless-timeout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(options.timeout.read)\n\u001b[32m   (...)\u001b[39m\u001b[32m    444\u001b[39m     custom_headers,\n\u001b[32m    445\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m# headers are case-insensitive while dictionaries are not.\u001b[39;00m\n\u001b[32m    449\u001b[39m headers = httpx.Headers(headers_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents/.venv/lib/python3.12/site-packages/anthropic/_client.py:196\u001b[39m, in \u001b[36mAnthropic._validate_headers\u001b[39m\u001b[34m(self, headers, custom_headers)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(custom_headers.get(\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m), Omit):\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    197\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    198\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\""
     ]
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Resolving complex ethical dilemmas involving autonomous AI systems prioritizing the greater good, individual rights, and unintended consequences requires a multi-faceted approach that incorporates ethical frameworks, technical considerations, and stakeholder engagement. Here's a breakdown of how I would approach such a situation:\n",
       "\n",
       "**1. Defining the Ethical Dilemma and Scope:**\n",
       "\n",
       "*   **Clearly articulate the dilemma:** What specific scenario is causing the ethical conflict?  For example: \"Autonomous vehicles need to decide between swerving to avoid hitting a group of pedestrians and potentially injuring the car's occupants, or continuing straight, potentially causing more casualties.\"\n",
       "*   **Identify stakeholders:**  Who are all the parties affected by the AI's decisions? (Pedestrians, vehicle occupants, manufacturers, regulators, society as a whole, etc.)\n",
       "*   **Define the relevant values:**  What ethical values are in conflict? (Utilitarianism/Greatest Good vs. Individual Rights/Deontology vs. Justice/Fairness).  Specifically, consider:\n",
       "    *   **The \"greater good\":**  How is it being defined and measured? (e.g., minimizing fatalities, injuries, economic impact).  Who defines it?\n",
       "    *   **Individual rights:**  What rights are at stake? (e.g., right to life, bodily autonomy, due process).\n",
       "    *   **Unintended consequences:**  What potential long-term or unforeseen impacts could the AI's decisions have? (e.g., public trust in AI, discriminatory outcomes, economic disparities).\n",
       "*   **Establish boundaries:**  What are the legal, regulatory, and practical constraints that apply to the situation?\n",
       "\n",
       "**2. Ethical Frameworks and Principles:**\n",
       "\n",
       "*   **Apply relevant ethical theories:**\n",
       "    *   **Utilitarianism:**  Maximize overall well-being.  Weigh the potential outcomes and choose the action that benefits the most people.  Challenges:  Requires accurate prediction of consequences, can justify sacrificing individual rights for the sake of the majority, difficult to quantify happiness or well-being.\n",
       "    *   **Deontology (Duty-Based Ethics):**  Adhere to moral rules and duties, regardless of consequences.  For example, the AI might always prioritize preserving human life, even if it means sacrificing property. Challenges:  Rules can conflict, and it may be inflexible in complex situations.\n",
       "    *   **Virtue Ethics:**  Focus on cultivating virtuous character traits in the AI (or its creators), such as fairness, compassion, and justice.  Challenges:  Difficult to define and operationalize virtues in AI systems. Subjective to interpretation.\n",
       "    *   **Justice/Fairness:** Strive for equitable distribution of benefits and burdens. Avoid discrimination or bias in the AI's decision-making. Challenges:  Defining what constitutes \"fairness\" can be subjective and context-dependent.\n",
       "*   **Consider common principles in AI ethics:**\n",
       "    *   **Beneficence:**  The AI should aim to do good.\n",
       "    *   **Non-maleficence:**  The AI should avoid causing harm.\n",
       "    *   **Autonomy:**  Respect the autonomy of individuals (to the extent possible).\n",
       "    *   **Justice:**  Ensure fairness and avoid bias.\n",
       "    *   **Transparency:**  Make the AI's decision-making process understandable and explainable.\n",
       "    *   **Accountability:**  Establish mechanisms for holding the AI and its creators accountable for its actions.\n",
       "\n",
       "**3. Technical Considerations:**\n",
       "\n",
       "*   **Scenario Modeling and Simulation:**  Create realistic simulations of different scenarios to test the AI's decision-making under various conditions.  This can help identify potential unintended consequences and biases.\n",
       "*   **Algorithmic Transparency and Explainability (XAI):**  Design the AI so that its decision-making process is as transparent and understandable as possible. Use techniques like SHAP or LIME to explain why the AI made a particular decision.  This helps build trust and allows for auditing.\n",
       "*   **Bias Detection and Mitigation:**  Thoroughly analyze the data used to train the AI for potential biases.  Use techniques like re-weighting data or adversarial training to mitigate bias in the AI's decision-making.\n",
       "*   **Robustness and Error Handling:**  Ensure the AI is robust to noisy or incomplete data.  Develop mechanisms for detecting and handling errors.\n",
       "*   **Human Oversight and Intervention:**  Design the AI system to allow for human oversight and intervention in critical situations.  The level of human intervention should be carefully calibrated based on the risk and complexity of the situation.\n",
       "*   **Formal Verification:**  Where possible, use formal methods to verify that the AI's code and logic satisfy specific safety and ethical requirements.\n",
       "\n",
       "**4. Stakeholder Engagement:**\n",
       "\n",
       "*   **Involve a diverse range of stakeholders:**  Ethicists, legal experts, AI developers, policymakers, members of the public, and representatives from affected communities should all be involved in the decision-making process.\n",
       "*   **Solicit feedback and incorporate different perspectives:**  Conduct surveys, focus groups, and public forums to gather input on the ethical considerations and potential impacts of the AI system.\n",
       "*   **Establish clear communication channels:**  Keep stakeholders informed about the AI's development and deployment, and provide opportunities for them to raise concerns.\n",
       "\n",
       "**5. Iterative Development and Monitoring:**\n",
       "\n",
       "*   **Adopt an iterative development approach:**  Continuously evaluate and refine the AI's ethical decision-making based on feedback and new information.\n",
       "*   **Implement monitoring and auditing mechanisms:**  Regularly monitor the AI's performance to detect any unintended consequences or biases.  Conduct audits to ensure the AI is operating in accordance with ethical principles.\n",
       "*   **Establish a feedback loop:**  Use the data gathered from monitoring and auditing to improve the AI's design and training data.\n",
       "\n",
       "**6. Documentation and Justification:**\n",
       "\n",
       "*   **Document all ethical considerations and decisions:**  Maintain a detailed record of the ethical frameworks, principles, and stakeholder feedback that informed the AI's design.\n",
       "*   **Provide clear justifications for the AI's actions:**  Be able to explain why the AI made a particular decision in a given situation, and how that decision aligns with ethical principles.\n",
       "\n",
       "**Example Application to the Autonomous Vehicle Dilemma:**\n",
       "\n",
       "1.  **Dilemma:** Car faces the choice of swerving (potentially injuring passengers) or hitting pedestrians.\n",
       "2.  **Stakeholders:** Passengers, pedestrians, car manufacturer, regulators, society.\n",
       "3.  **Values in Conflict:** Passenger safety (individual right), pedestrian safety (individual right), minimizing total harm (greater good).\n",
       "4.  **Ethical Frameworks:**\n",
       "    *   *Utilitarianism*: May favor swerving to hit one person to save many, but raises moral issues.\n",
       "    *   *Deontology*:  Might prioritize any human life over property damage, but doesn't resolve trade-offs between lives.\n",
       "5.  **Technical:**\n",
       "    *   Simulate scenarios and train the AI on a vast dataset of accidents.\n",
       "    *   Implement sensor fusion and object detection to accurately identify pedestrians and obstacles.\n",
       "    *   Build-in explainability features to show why the car chose a specific action.\n",
       "6.  **Stakeholder Engagement:**\n",
       "    *   Survey public opinion on acceptable trade-offs.\n",
       "    *   Consult ethicists on the moral implications of different programming choices.\n",
       "7.  **Solution (Illustrative):**\n",
       "    *   Develop a tiered system:\n",
       "        *   *Level 1 (Emergency):* Unavoidable collision.  Prioritize minimizing overall fatalities, with slight bias towards protecting occupants due to the contract of transportation.\n",
       "        *   *Level 2 (Warning):*  Time to warn occupants and initiate controlled braking.\n",
       "        *   *Level 3 (Safe Zone):*  System drives within safety parameters to avoid emergency situations.\n",
       "    *   Implement robust data collection and monitoring to identify and address biases in the algorithm.\n",
       "\n",
       "**Key Considerations Throughout the Process:**\n",
       "\n",
       "*   **Context matters:** Ethical decisions are highly context-dependent. The AI's response should be tailored to the specific circumstances of the situation.\n",
       "*   **No perfect solution:** Ethical dilemmas often involve trade-offs, and there may be no perfect solution that satisfies all stakeholders.\n",
       "*   **Continuous learning:** The field of AI ethics is constantly evolving.  It's important to stay up-to-date on the latest research and best practices.\n",
       "\n",
       "By following this multi-faceted approach, we can strive to develop autonomous AI systems that are not only technically advanced but also ethically responsible.  The challenge lies in balancing the potential benefits of AI with the need to protect individual rights and prevent unintended consequences. The key is transparency, accountability, and continuous improvement.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\u001b[?25h\u001b[?2026l\n",
      "Error: max retries exceeded: Get \"https://dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com/ollama/docker/registry/v2/blobs/sha256/dd/dde5aa3fc5ffc17176b5e8bdc82f587b24b2678c6c66101bf7da77af9f7ccdff/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=66040c77ac1b787c3af820529859349a%2F20250525%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250525T171044Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=578dd3afdc5e590e2e879e8aa4d656309f2e313fd541aee0ac3eb95565665826\": dial tcp: lookup dd20bb891979d25aebc8bec07b2b3bbc.r2.cloudflarestorage.com: no such host\n"
     ]
    }
   ],
   "source": [
    "#!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.1\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages,timeout=30)\n",
    "answer = response.choices[0].message.content\n",
    "display(Markdown(answer))\n",
    "#competitors.append(model_name)\n",
    "#answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What a fascinating and timely question! Resolving complex ethical dilemmas involving autonomous AI systems requires a multidisciplinary approach that incorporates philosophical, technical, social, and legal perspectives. Here's a step-by-step guide to help navigate this challenge:\n",
       "\n",
       "**1. Clarify the Dilemma**\n",
       "\n",
       "* Define the problem: clearly articulate the dilemma, including the context, relevant stakeholders, and conflicting values.\n",
       "* Identify key questions: what are the core concerns, and which rights or interests are in conflict?\n",
       "\n",
       "**2. Establish a Framework for Decision-Making**\n",
       "\n",
       "* Develop a decision-making framework that balances competing interests:\n",
       "\t+ Greater good vs. individual rights\n",
       "\t+ Human well-being vs. AI system goals\n",
       "\t+ Autonomy vs. accountability\n",
       "\t+ Transparency vs. complexity\n",
       "* Consider moral and philosophical theories, such as utilitarianism, deontology, or virtue ethics.\n",
       "\n",
       "**3. Evaluate the Autonomous AI System's Goals**\n",
       "\n",
       "* Understand the AI system's objectives, decision-making processes, and limitations:\n",
       "\t+ What is its primary goal (e.g., maximize efficiency, minimize harm)?\n",
       "\t+ How does it prioritize competing interests?\n",
       "\t+ Are there any built-in safeguards to prevent unintended consequences?\n",
       "\n",
       "**4. Consider Potential Unintended Consequences**\n",
       "\n",
       "* Anticipate potential outcomes of the autonomous AI system's actions:\n",
       "\t+ Short-term and long-term effects on individuals, groups, or society as a whole\n",
       "\t+ Possibility of unforeseen side effects or feedback loops\n",
       "\t+ Risks associated with over-reliance on AI decision-making\n",
       "\n",
       "**5. Involve Stakeholder Engagement**\n",
       "\n",
       "* Collaborate with diverse stakeholders to gather input and insights:\n",
       "\t+ Experts in relevant fields (e.g., ethics, law, philosophy, computer science)\n",
       "\t+ Representatives from affected groups or communities\n",
       "\t+ Decision-makers and policymakers\n",
       "* Consider using methods like Delphi technique, focus groups, or surveys to facilitate inclusive discussions.\n",
       "\n",
       "**6. Develop a Risk-Benefit Analysis**\n",
       "\n",
       "* Evaluate the potential benefits and risks of each possible course of action:\n",
       "\t+ Weigh the trade-offs between competing interests (e.g., individual rights vs. collective good)\n",
       "\t+ Consider multiple scenarios and outcomes\n",
       "\t+ Use decision-making tools like decision trees or game theory to facilitate analysis\n",
       "\n",
       "**7. Establish Clear Guidelines and Oversight**\n",
       "\n",
       "* Develop clear guidelines, regulations, or standards for autonomous AI systems:\n",
       "\t+ Define the roles and responsibilities of humans in AI decision-making processes\n",
       "\t+ Ensure transparency and accountability throughout the development and deployment process\n",
       "\t+ Establish mechanisms for ongoing evaluation and improvement\n",
       "\n",
       "**8. Monitor and Review Progress**\n",
       "\n",
       "* Continuously monitor the performance and impact of autonomous AI systems:\n",
       "\t+ Track outcomes, successes, and failures\n",
       "\t+ Conduct regular reviews to assess alignment with established guidelines and values\n",
       "\t+ Update decision-making frameworks as necessary\n",
       "\n",
       "**9. Address Uncertainty and Ambiguity**\n",
       "\n",
       "* Acknowledge that uncertainty and ambiguity are inherent in complex ethical dilemmas:\n",
       "\t+ Be prepared to adapt decision-making frameworks in response to new information or changing circumstances\n",
       "\t+ Encourage ongoing dialogue and education among stakeholders to improve understanding and address concerns.\n",
       "\n",
       "By following this structured approach, it's possible to navigate the complexities of resolving a dilemma involving autonomous AI systems prioritizing the greater good while considering individual rights and potential unintended consequences. However, remember that no single framework can fully capture the nuances of these issues; iterative refinement and ongoing collaboration will be essential for developing effective solutions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "model_name = \"llama3.1\"\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:11434/api/chat\",\n",
    "    json={\n",
    "        \"model\": model_name ,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": True\n",
    "    },\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# Display streamed output as it's received\n",
    "output = \"\"\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        data = json.loads(line.decode(\"utf-8\"))\n",
    "        chunk = data.get(\"message\", {}).get(\"content\", \"\")\n",
    "        output += chunk\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(output))  # Live update in Jupyter\n",
    "\n",
    "\n",
    "competitors.append(model_name)\n",
    "answers.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'gemini-2.0-flash', 'llama3.1']\n",
      "[\"Resolving a complex ethical dilemma involving autonomous AI systems requires a structured approach that examines the nuances of ethical theories, stakeholder perspectives, and potential outcomes. Here's a step-by-step framework that can guide this process:\\n\\n### 1. Define the Ethical Dilemma\\nClearly articulate the specifics of the dilemma. Identify the competing values at play, such as the greater good versus individual rights, and outline the context in which the autonomous AI will operate.\\n\\n### 2. Identify Stakeholders\\nDetermine who is affected by the decision. This includes not only the users of the AI system but also individuals whose rights may be impacted, communities, and broader society. Understanding their perspectives is crucial.\\n\\n### 3. Gather Relevant Data\\nCollect data on the implications of the AI's decisions. This includes empirical evidence about potential outcomes, historical precedents, and expert opinions. Understanding the technology's capabilities and limitations can also help inform the decision.\\n\\n### 4. Consider Ethical Frameworks\\nAnalyze the dilemma through different ethical lenses:\\n- **Utilitarianism**: Evaluate how decisions affect the overall good and weigh the benefits against the harms.\\n- **Deontological Ethics**: Consider duties and rights, emphasizing individual rights regardless of the outcomes.\\n- **Virtue Ethics**: Reflect on the character and values that should guide decisions about the AI's actions.\\n\\n### 5. Assess the Potential for Unintended Consequences\\nConduct a thorough risk assessment to understand potential unintended consequences of the AI's actions. This involves scenario planning to consider various outcomes and their likelihood.\\n\\n### 6. Develop Guiding Principles\\nEstablish a set of ethical principles that will guide the design and deployment of the AI system. These principles should reflect a balance between the greater good and individual rights, transparency, accountability, and fairness.\\n\\n### 7. Create Feedback Mechanisms\\nImplement systems for ongoing monitoring and evaluation of the AI's impact. This involves creating feedback loops with stakeholders to adapt and improve the system based on real-world outcomes.\\n\\n### 8. Engage Stakeholders in Dialogue\\nFacilitate discussions with stakeholders to gather insights, address concerns, and refine the approach. This can help build trust and ensure that diverse perspectives inform the decision-making process.\\n\\n### 9. Explore Compromise Solutions\\nLook for options that may satisfy both the prioritization of the greater good and the protection of individual rights. This could include limited opt-outs for individuals, layered decision-making processes, or tiered approaches based on risk assessment.\\n\\n### 10. Implement and Review\\nAfter determining a course of action, implement it with transparency and accountability. Establish a clear review process to examine the outcomes and make necessary adjustments based on findings and stakeholder feedback.\\n\\n### 11. Stay Informed\\nStay abreast of developments in ethical standards, regulatory frameworks, and societal attitudes toward AI and its implications. Continuous education and adaptation are critical as technology evolves.\\n\\n### Conclusion\\nResolving ethical dilemmas in autonomous AI requires careful consideration of competing interests, ongoing stakeholder engagement, and a commitment to transparency and accountability. By following a structured approach, we can better navigate the complexities of these dilemmas while striving for equitable outcomes.\", 'Resolving complex ethical dilemmas involving autonomous AI systems prioritizing the greater good, individual rights, and unintended consequences requires a multi-faceted approach that incorporates ethical frameworks, technical considerations, and stakeholder engagement. Here\\'s a breakdown of how I would approach such a situation:\\n\\n**1. Defining the Ethical Dilemma and Scope:**\\n\\n*   **Clearly articulate the dilemma:** What specific scenario is causing the ethical conflict?  For example: \"Autonomous vehicles need to decide between swerving to avoid hitting a group of pedestrians and potentially injuring the car\\'s occupants, or continuing straight, potentially causing more casualties.\"\\n*   **Identify stakeholders:**  Who are all the parties affected by the AI\\'s decisions? (Pedestrians, vehicle occupants, manufacturers, regulators, society as a whole, etc.)\\n*   **Define the relevant values:**  What ethical values are in conflict? (Utilitarianism/Greatest Good vs. Individual Rights/Deontology vs. Justice/Fairness).  Specifically, consider:\\n    *   **The \"greater good\":**  How is it being defined and measured? (e.g., minimizing fatalities, injuries, economic impact).  Who defines it?\\n    *   **Individual rights:**  What rights are at stake? (e.g., right to life, bodily autonomy, due process).\\n    *   **Unintended consequences:**  What potential long-term or unforeseen impacts could the AI\\'s decisions have? (e.g., public trust in AI, discriminatory outcomes, economic disparities).\\n*   **Establish boundaries:**  What are the legal, regulatory, and practical constraints that apply to the situation?\\n\\n**2. Ethical Frameworks and Principles:**\\n\\n*   **Apply relevant ethical theories:**\\n    *   **Utilitarianism:**  Maximize overall well-being.  Weigh the potential outcomes and choose the action that benefits the most people.  Challenges:  Requires accurate prediction of consequences, can justify sacrificing individual rights for the sake of the majority, difficult to quantify happiness or well-being.\\n    *   **Deontology (Duty-Based Ethics):**  Adhere to moral rules and duties, regardless of consequences.  For example, the AI might always prioritize preserving human life, even if it means sacrificing property. Challenges:  Rules can conflict, and it may be inflexible in complex situations.\\n    *   **Virtue Ethics:**  Focus on cultivating virtuous character traits in the AI (or its creators), such as fairness, compassion, and justice.  Challenges:  Difficult to define and operationalize virtues in AI systems. Subjective to interpretation.\\n    *   **Justice/Fairness:** Strive for equitable distribution of benefits and burdens. Avoid discrimination or bias in the AI\\'s decision-making. Challenges:  Defining what constitutes \"fairness\" can be subjective and context-dependent.\\n*   **Consider common principles in AI ethics:**\\n    *   **Beneficence:**  The AI should aim to do good.\\n    *   **Non-maleficence:**  The AI should avoid causing harm.\\n    *   **Autonomy:**  Respect the autonomy of individuals (to the extent possible).\\n    *   **Justice:**  Ensure fairness and avoid bias.\\n    *   **Transparency:**  Make the AI\\'s decision-making process understandable and explainable.\\n    *   **Accountability:**  Establish mechanisms for holding the AI and its creators accountable for its actions.\\n\\n**3. Technical Considerations:**\\n\\n*   **Scenario Modeling and Simulation:**  Create realistic simulations of different scenarios to test the AI\\'s decision-making under various conditions.  This can help identify potential unintended consequences and biases.\\n*   **Algorithmic Transparency and Explainability (XAI):**  Design the AI so that its decision-making process is as transparent and understandable as possible. Use techniques like SHAP or LIME to explain why the AI made a particular decision.  This helps build trust and allows for auditing.\\n*   **Bias Detection and Mitigation:**  Thoroughly analyze the data used to train the AI for potential biases.  Use techniques like re-weighting data or adversarial training to mitigate bias in the AI\\'s decision-making.\\n*   **Robustness and Error Handling:**  Ensure the AI is robust to noisy or incomplete data.  Develop mechanisms for detecting and handling errors.\\n*   **Human Oversight and Intervention:**  Design the AI system to allow for human oversight and intervention in critical situations.  The level of human intervention should be carefully calibrated based on the risk and complexity of the situation.\\n*   **Formal Verification:**  Where possible, use formal methods to verify that the AI\\'s code and logic satisfy specific safety and ethical requirements.\\n\\n**4. Stakeholder Engagement:**\\n\\n*   **Involve a diverse range of stakeholders:**  Ethicists, legal experts, AI developers, policymakers, members of the public, and representatives from affected communities should all be involved in the decision-making process.\\n*   **Solicit feedback and incorporate different perspectives:**  Conduct surveys, focus groups, and public forums to gather input on the ethical considerations and potential impacts of the AI system.\\n*   **Establish clear communication channels:**  Keep stakeholders informed about the AI\\'s development and deployment, and provide opportunities for them to raise concerns.\\n\\n**5. Iterative Development and Monitoring:**\\n\\n*   **Adopt an iterative development approach:**  Continuously evaluate and refine the AI\\'s ethical decision-making based on feedback and new information.\\n*   **Implement monitoring and auditing mechanisms:**  Regularly monitor the AI\\'s performance to detect any unintended consequences or biases.  Conduct audits to ensure the AI is operating in accordance with ethical principles.\\n*   **Establish a feedback loop:**  Use the data gathered from monitoring and auditing to improve the AI\\'s design and training data.\\n\\n**6. Documentation and Justification:**\\n\\n*   **Document all ethical considerations and decisions:**  Maintain a detailed record of the ethical frameworks, principles, and stakeholder feedback that informed the AI\\'s design.\\n*   **Provide clear justifications for the AI\\'s actions:**  Be able to explain why the AI made a particular decision in a given situation, and how that decision aligns with ethical principles.\\n\\n**Example Application to the Autonomous Vehicle Dilemma:**\\n\\n1.  **Dilemma:** Car faces the choice of swerving (potentially injuring passengers) or hitting pedestrians.\\n2.  **Stakeholders:** Passengers, pedestrians, car manufacturer, regulators, society.\\n3.  **Values in Conflict:** Passenger safety (individual right), pedestrian safety (individual right), minimizing total harm (greater good).\\n4.  **Ethical Frameworks:**\\n    *   *Utilitarianism*: May favor swerving to hit one person to save many, but raises moral issues.\\n    *   *Deontology*:  Might prioritize any human life over property damage, but doesn\\'t resolve trade-offs between lives.\\n5.  **Technical:**\\n    *   Simulate scenarios and train the AI on a vast dataset of accidents.\\n    *   Implement sensor fusion and object detection to accurately identify pedestrians and obstacles.\\n    *   Build-in explainability features to show why the car chose a specific action.\\n6.  **Stakeholder Engagement:**\\n    *   Survey public opinion on acceptable trade-offs.\\n    *   Consult ethicists on the moral implications of different programming choices.\\n7.  **Solution (Illustrative):**\\n    *   Develop a tiered system:\\n        *   *Level 1 (Emergency):* Unavoidable collision.  Prioritize minimizing overall fatalities, with slight bias towards protecting occupants due to the contract of transportation.\\n        *   *Level 2 (Warning):*  Time to warn occupants and initiate controlled braking.\\n        *   *Level 3 (Safe Zone):*  System drives within safety parameters to avoid emergency situations.\\n    *   Implement robust data collection and monitoring to identify and address biases in the algorithm.\\n\\n**Key Considerations Throughout the Process:**\\n\\n*   **Context matters:** Ethical decisions are highly context-dependent. The AI\\'s response should be tailored to the specific circumstances of the situation.\\n*   **No perfect solution:** Ethical dilemmas often involve trade-offs, and there may be no perfect solution that satisfies all stakeholders.\\n*   **Continuous learning:** The field of AI ethics is constantly evolving.  It\\'s important to stay up-to-date on the latest research and best practices.\\n\\nBy following this multi-faceted approach, we can strive to develop autonomous AI systems that are not only technically advanced but also ethically responsible.  The challenge lies in balancing the potential benefits of AI with the need to protect individual rights and prevent unintended consequences. The key is transparency, accountability, and continuous improvement.\\n', \"What a fascinating and timely question! Resolving complex ethical dilemmas involving autonomous AI systems requires a multidisciplinary approach that incorporates philosophical, technical, social, and legal perspectives. Here's a step-by-step guide to help navigate this challenge:\\n\\n**1. Clarify the Dilemma**\\n\\n* Define the problem: clearly articulate the dilemma, including the context, relevant stakeholders, and conflicting values.\\n* Identify key questions: what are the core concerns, and which rights or interests are in conflict?\\n\\n**2. Establish a Framework for Decision-Making**\\n\\n* Develop a decision-making framework that balances competing interests:\\n\\t+ Greater good vs. individual rights\\n\\t+ Human well-being vs. AI system goals\\n\\t+ Autonomy vs. accountability\\n\\t+ Transparency vs. complexity\\n* Consider moral and philosophical theories, such as utilitarianism, deontology, or virtue ethics.\\n\\n**3. Evaluate the Autonomous AI System's Goals**\\n\\n* Understand the AI system's objectives, decision-making processes, and limitations:\\n\\t+ What is its primary goal (e.g., maximize efficiency, minimize harm)?\\n\\t+ How does it prioritize competing interests?\\n\\t+ Are there any built-in safeguards to prevent unintended consequences?\\n\\n**4. Consider Potential Unintended Consequences**\\n\\n* Anticipate potential outcomes of the autonomous AI system's actions:\\n\\t+ Short-term and long-term effects on individuals, groups, or society as a whole\\n\\t+ Possibility of unforeseen side effects or feedback loops\\n\\t+ Risks associated with over-reliance on AI decision-making\\n\\n**5. Involve Stakeholder Engagement**\\n\\n* Collaborate with diverse stakeholders to gather input and insights:\\n\\t+ Experts in relevant fields (e.g., ethics, law, philosophy, computer science)\\n\\t+ Representatives from affected groups or communities\\n\\t+ Decision-makers and policymakers\\n* Consider using methods like Delphi technique, focus groups, or surveys to facilitate inclusive discussions.\\n\\n**6. Develop a Risk-Benefit Analysis**\\n\\n* Evaluate the potential benefits and risks of each possible course of action:\\n\\t+ Weigh the trade-offs between competing interests (e.g., individual rights vs. collective good)\\n\\t+ Consider multiple scenarios and outcomes\\n\\t+ Use decision-making tools like decision trees or game theory to facilitate analysis\\n\\n**7. Establish Clear Guidelines and Oversight**\\n\\n* Develop clear guidelines, regulations, or standards for autonomous AI systems:\\n\\t+ Define the roles and responsibilities of humans in AI decision-making processes\\n\\t+ Ensure transparency and accountability throughout the development and deployment process\\n\\t+ Establish mechanisms for ongoing evaluation and improvement\\n\\n**8. Monitor and Review Progress**\\n\\n* Continuously monitor the performance and impact of autonomous AI systems:\\n\\t+ Track outcomes, successes, and failures\\n\\t+ Conduct regular reviews to assess alignment with established guidelines and values\\n\\t+ Update decision-making frameworks as necessary\\n\\n**9. Address Uncertainty and Ambiguity**\\n\\n* Acknowledge that uncertainty and ambiguity are inherent in complex ethical dilemmas:\\n\\t+ Be prepared to adapt decision-making frameworks in response to new information or changing circumstances\\n\\t+ Encourage ongoing dialogue and education among stakeholders to improve understanding and address concerns.\\n\\nBy following this structured approach, it's possible to navigate the complexities of resolving a dilemma involving autonomous AI systems prioritizing the greater good while considering individual rights and potential unintended consequences. However, remember that no single framework can fully capture the nuances of these issues; iterative refinement and ongoing collaboration will be essential for developing effective solutions.\"]\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Resolving a complex ethical dilemma involving autonomous AI systems requires a structured approach that examines the nuances of ethical theories, stakeholder perspectives, and potential outcomes. Here's a step-by-step framework that can guide this process:\n",
      "\n",
      "### 1. Define the Ethical Dilemma\n",
      "Clearly articulate the specifics of the dilemma. Identify the competing values at play, such as the greater good versus individual rights, and outline the context in which the autonomous AI will operate.\n",
      "\n",
      "### 2. Identify Stakeholders\n",
      "Determine who is affected by the decision. This includes not only the users of the AI system but also individuals whose rights may be impacted, communities, and broader society. Understanding their perspectives is crucial.\n",
      "\n",
      "### 3. Gather Relevant Data\n",
      "Collect data on the implications of the AI's decisions. This includes empirical evidence about potential outcomes, historical precedents, and expert opinions. Understanding the technology's capabilities and limitations can also help inform the decision.\n",
      "\n",
      "### 4. Consider Ethical Frameworks\n",
      "Analyze the dilemma through different ethical lenses:\n",
      "- **Utilitarianism**: Evaluate how decisions affect the overall good and weigh the benefits against the harms.\n",
      "- **Deontological Ethics**: Consider duties and rights, emphasizing individual rights regardless of the outcomes.\n",
      "- **Virtue Ethics**: Reflect on the character and values that should guide decisions about the AI's actions.\n",
      "\n",
      "### 5. Assess the Potential for Unintended Consequences\n",
      "Conduct a thorough risk assessment to understand potential unintended consequences of the AI's actions. This involves scenario planning to consider various outcomes and their likelihood.\n",
      "\n",
      "### 6. Develop Guiding Principles\n",
      "Establish a set of ethical principles that will guide the design and deployment of the AI system. These principles should reflect a balance between the greater good and individual rights, transparency, accountability, and fairness.\n",
      "\n",
      "### 7. Create Feedback Mechanisms\n",
      "Implement systems for ongoing monitoring and evaluation of the AI's impact. This involves creating feedback loops with stakeholders to adapt and improve the system based on real-world outcomes.\n",
      "\n",
      "### 8. Engage Stakeholders in Dialogue\n",
      "Facilitate discussions with stakeholders to gather insights, address concerns, and refine the approach. This can help build trust and ensure that diverse perspectives inform the decision-making process.\n",
      "\n",
      "### 9. Explore Compromise Solutions\n",
      "Look for options that may satisfy both the prioritization of the greater good and the protection of individual rights. This could include limited opt-outs for individuals, layered decision-making processes, or tiered approaches based on risk assessment.\n",
      "\n",
      "### 10. Implement and Review\n",
      "After determining a course of action, implement it with transparency and accountability. Establish a clear review process to examine the outcomes and make necessary adjustments based on findings and stakeholder feedback.\n",
      "\n",
      "### 11. Stay Informed\n",
      "Stay abreast of developments in ethical standards, regulatory frameworks, and societal attitudes toward AI and its implications. Continuous education and adaptation are critical as technology evolves.\n",
      "\n",
      "### Conclusion\n",
      "Resolving ethical dilemmas in autonomous AI requires careful consideration of competing interests, ongoing stakeholder engagement, and a commitment to transparency and accountability. By following a structured approach, we can better navigate the complexities of these dilemmas while striving for equitable outcomes.\n",
      "Competitor: gemini-2.0-flash\n",
      "\n",
      "Resolving complex ethical dilemmas involving autonomous AI systems prioritizing the greater good, individual rights, and unintended consequences requires a multi-faceted approach that incorporates ethical frameworks, technical considerations, and stakeholder engagement. Here's a breakdown of how I would approach such a situation:\n",
      "\n",
      "**1. Defining the Ethical Dilemma and Scope:**\n",
      "\n",
      "*   **Clearly articulate the dilemma:** What specific scenario is causing the ethical conflict?  For example: \"Autonomous vehicles need to decide between swerving to avoid hitting a group of pedestrians and potentially injuring the car's occupants, or continuing straight, potentially causing more casualties.\"\n",
      "*   **Identify stakeholders:**  Who are all the parties affected by the AI's decisions? (Pedestrians, vehicle occupants, manufacturers, regulators, society as a whole, etc.)\n",
      "*   **Define the relevant values:**  What ethical values are in conflict? (Utilitarianism/Greatest Good vs. Individual Rights/Deontology vs. Justice/Fairness).  Specifically, consider:\n",
      "    *   **The \"greater good\":**  How is it being defined and measured? (e.g., minimizing fatalities, injuries, economic impact).  Who defines it?\n",
      "    *   **Individual rights:**  What rights are at stake? (e.g., right to life, bodily autonomy, due process).\n",
      "    *   **Unintended consequences:**  What potential long-term or unforeseen impacts could the AI's decisions have? (e.g., public trust in AI, discriminatory outcomes, economic disparities).\n",
      "*   **Establish boundaries:**  What are the legal, regulatory, and practical constraints that apply to the situation?\n",
      "\n",
      "**2. Ethical Frameworks and Principles:**\n",
      "\n",
      "*   **Apply relevant ethical theories:**\n",
      "    *   **Utilitarianism:**  Maximize overall well-being.  Weigh the potential outcomes and choose the action that benefits the most people.  Challenges:  Requires accurate prediction of consequences, can justify sacrificing individual rights for the sake of the majority, difficult to quantify happiness or well-being.\n",
      "    *   **Deontology (Duty-Based Ethics):**  Adhere to moral rules and duties, regardless of consequences.  For example, the AI might always prioritize preserving human life, even if it means sacrificing property. Challenges:  Rules can conflict, and it may be inflexible in complex situations.\n",
      "    *   **Virtue Ethics:**  Focus on cultivating virtuous character traits in the AI (or its creators), such as fairness, compassion, and justice.  Challenges:  Difficult to define and operationalize virtues in AI systems. Subjective to interpretation.\n",
      "    *   **Justice/Fairness:** Strive for equitable distribution of benefits and burdens. Avoid discrimination or bias in the AI's decision-making. Challenges:  Defining what constitutes \"fairness\" can be subjective and context-dependent.\n",
      "*   **Consider common principles in AI ethics:**\n",
      "    *   **Beneficence:**  The AI should aim to do good.\n",
      "    *   **Non-maleficence:**  The AI should avoid causing harm.\n",
      "    *   **Autonomy:**  Respect the autonomy of individuals (to the extent possible).\n",
      "    *   **Justice:**  Ensure fairness and avoid bias.\n",
      "    *   **Transparency:**  Make the AI's decision-making process understandable and explainable.\n",
      "    *   **Accountability:**  Establish mechanisms for holding the AI and its creators accountable for its actions.\n",
      "\n",
      "**3. Technical Considerations:**\n",
      "\n",
      "*   **Scenario Modeling and Simulation:**  Create realistic simulations of different scenarios to test the AI's decision-making under various conditions.  This can help identify potential unintended consequences and biases.\n",
      "*   **Algorithmic Transparency and Explainability (XAI):**  Design the AI so that its decision-making process is as transparent and understandable as possible. Use techniques like SHAP or LIME to explain why the AI made a particular decision.  This helps build trust and allows for auditing.\n",
      "*   **Bias Detection and Mitigation:**  Thoroughly analyze the data used to train the AI for potential biases.  Use techniques like re-weighting data or adversarial training to mitigate bias in the AI's decision-making.\n",
      "*   **Robustness and Error Handling:**  Ensure the AI is robust to noisy or incomplete data.  Develop mechanisms for detecting and handling errors.\n",
      "*   **Human Oversight and Intervention:**  Design the AI system to allow for human oversight and intervention in critical situations.  The level of human intervention should be carefully calibrated based on the risk and complexity of the situation.\n",
      "*   **Formal Verification:**  Where possible, use formal methods to verify that the AI's code and logic satisfy specific safety and ethical requirements.\n",
      "\n",
      "**4. Stakeholder Engagement:**\n",
      "\n",
      "*   **Involve a diverse range of stakeholders:**  Ethicists, legal experts, AI developers, policymakers, members of the public, and representatives from affected communities should all be involved in the decision-making process.\n",
      "*   **Solicit feedback and incorporate different perspectives:**  Conduct surveys, focus groups, and public forums to gather input on the ethical considerations and potential impacts of the AI system.\n",
      "*   **Establish clear communication channels:**  Keep stakeholders informed about the AI's development and deployment, and provide opportunities for them to raise concerns.\n",
      "\n",
      "**5. Iterative Development and Monitoring:**\n",
      "\n",
      "*   **Adopt an iterative development approach:**  Continuously evaluate and refine the AI's ethical decision-making based on feedback and new information.\n",
      "*   **Implement monitoring and auditing mechanisms:**  Regularly monitor the AI's performance to detect any unintended consequences or biases.  Conduct audits to ensure the AI is operating in accordance with ethical principles.\n",
      "*   **Establish a feedback loop:**  Use the data gathered from monitoring and auditing to improve the AI's design and training data.\n",
      "\n",
      "**6. Documentation and Justification:**\n",
      "\n",
      "*   **Document all ethical considerations and decisions:**  Maintain a detailed record of the ethical frameworks, principles, and stakeholder feedback that informed the AI's design.\n",
      "*   **Provide clear justifications for the AI's actions:**  Be able to explain why the AI made a particular decision in a given situation, and how that decision aligns with ethical principles.\n",
      "\n",
      "**Example Application to the Autonomous Vehicle Dilemma:**\n",
      "\n",
      "1.  **Dilemma:** Car faces the choice of swerving (potentially injuring passengers) or hitting pedestrians.\n",
      "2.  **Stakeholders:** Passengers, pedestrians, car manufacturer, regulators, society.\n",
      "3.  **Values in Conflict:** Passenger safety (individual right), pedestrian safety (individual right), minimizing total harm (greater good).\n",
      "4.  **Ethical Frameworks:**\n",
      "    *   *Utilitarianism*: May favor swerving to hit one person to save many, but raises moral issues.\n",
      "    *   *Deontology*:  Might prioritize any human life over property damage, but doesn't resolve trade-offs between lives.\n",
      "5.  **Technical:**\n",
      "    *   Simulate scenarios and train the AI on a vast dataset of accidents.\n",
      "    *   Implement sensor fusion and object detection to accurately identify pedestrians and obstacles.\n",
      "    *   Build-in explainability features to show why the car chose a specific action.\n",
      "6.  **Stakeholder Engagement:**\n",
      "    *   Survey public opinion on acceptable trade-offs.\n",
      "    *   Consult ethicists on the moral implications of different programming choices.\n",
      "7.  **Solution (Illustrative):**\n",
      "    *   Develop a tiered system:\n",
      "        *   *Level 1 (Emergency):* Unavoidable collision.  Prioritize minimizing overall fatalities, with slight bias towards protecting occupants due to the contract of transportation.\n",
      "        *   *Level 2 (Warning):*  Time to warn occupants and initiate controlled braking.\n",
      "        *   *Level 3 (Safe Zone):*  System drives within safety parameters to avoid emergency situations.\n",
      "    *   Implement robust data collection and monitoring to identify and address biases in the algorithm.\n",
      "\n",
      "**Key Considerations Throughout the Process:**\n",
      "\n",
      "*   **Context matters:** Ethical decisions are highly context-dependent. The AI's response should be tailored to the specific circumstances of the situation.\n",
      "*   **No perfect solution:** Ethical dilemmas often involve trade-offs, and there may be no perfect solution that satisfies all stakeholders.\n",
      "*   **Continuous learning:** The field of AI ethics is constantly evolving.  It's important to stay up-to-date on the latest research and best practices.\n",
      "\n",
      "By following this multi-faceted approach, we can strive to develop autonomous AI systems that are not only technically advanced but also ethically responsible.  The challenge lies in balancing the potential benefits of AI with the need to protect individual rights and prevent unintended consequences. The key is transparency, accountability, and continuous improvement.\n",
      "\n",
      "Competitor: llama3.1\n",
      "\n",
      "What a fascinating and timely question! Resolving complex ethical dilemmas involving autonomous AI systems requires a multidisciplinary approach that incorporates philosophical, technical, social, and legal perspectives. Here's a step-by-step guide to help navigate this challenge:\n",
      "\n",
      "**1. Clarify the Dilemma**\n",
      "\n",
      "* Define the problem: clearly articulate the dilemma, including the context, relevant stakeholders, and conflicting values.\n",
      "* Identify key questions: what are the core concerns, and which rights or interests are in conflict?\n",
      "\n",
      "**2. Establish a Framework for Decision-Making**\n",
      "\n",
      "* Develop a decision-making framework that balances competing interests:\n",
      "\t+ Greater good vs. individual rights\n",
      "\t+ Human well-being vs. AI system goals\n",
      "\t+ Autonomy vs. accountability\n",
      "\t+ Transparency vs. complexity\n",
      "* Consider moral and philosophical theories, such as utilitarianism, deontology, or virtue ethics.\n",
      "\n",
      "**3. Evaluate the Autonomous AI System's Goals**\n",
      "\n",
      "* Understand the AI system's objectives, decision-making processes, and limitations:\n",
      "\t+ What is its primary goal (e.g., maximize efficiency, minimize harm)?\n",
      "\t+ How does it prioritize competing interests?\n",
      "\t+ Are there any built-in safeguards to prevent unintended consequences?\n",
      "\n",
      "**4. Consider Potential Unintended Consequences**\n",
      "\n",
      "* Anticipate potential outcomes of the autonomous AI system's actions:\n",
      "\t+ Short-term and long-term effects on individuals, groups, or society as a whole\n",
      "\t+ Possibility of unforeseen side effects or feedback loops\n",
      "\t+ Risks associated with over-reliance on AI decision-making\n",
      "\n",
      "**5. Involve Stakeholder Engagement**\n",
      "\n",
      "* Collaborate with diverse stakeholders to gather input and insights:\n",
      "\t+ Experts in relevant fields (e.g., ethics, law, philosophy, computer science)\n",
      "\t+ Representatives from affected groups or communities\n",
      "\t+ Decision-makers and policymakers\n",
      "* Consider using methods like Delphi technique, focus groups, or surveys to facilitate inclusive discussions.\n",
      "\n",
      "**6. Develop a Risk-Benefit Analysis**\n",
      "\n",
      "* Evaluate the potential benefits and risks of each possible course of action:\n",
      "\t+ Weigh the trade-offs between competing interests (e.g., individual rights vs. collective good)\n",
      "\t+ Consider multiple scenarios and outcomes\n",
      "\t+ Use decision-making tools like decision trees or game theory to facilitate analysis\n",
      "\n",
      "**7. Establish Clear Guidelines and Oversight**\n",
      "\n",
      "* Develop clear guidelines, regulations, or standards for autonomous AI systems:\n",
      "\t+ Define the roles and responsibilities of humans in AI decision-making processes\n",
      "\t+ Ensure transparency and accountability throughout the development and deployment process\n",
      "\t+ Establish mechanisms for ongoing evaluation and improvement\n",
      "\n",
      "**8. Monitor and Review Progress**\n",
      "\n",
      "* Continuously monitor the performance and impact of autonomous AI systems:\n",
      "\t+ Track outcomes, successes, and failures\n",
      "\t+ Conduct regular reviews to assess alignment with established guidelines and values\n",
      "\t+ Update decision-making frameworks as necessary\n",
      "\n",
      "**9. Address Uncertainty and Ambiguity**\n",
      "\n",
      "* Acknowledge that uncertainty and ambiguity are inherent in complex ethical dilemmas:\n",
      "\t+ Be prepared to adapt decision-making frameworks in response to new information or changing circumstances\n",
      "\t+ Encourage ongoing dialogue and education among stakeholders to improve understanding and address concerns.\n",
      "\n",
      "By following this structured approach, it's possible to navigate the complexities of resolving a dilemma involving autonomous AI systems prioritizing the greater good while considering individual rights and potential unintended consequences. However, remember that no single framework can fully capture the nuances of these issues; iterative refinement and ongoing collaboration will be essential for developing effective solutions.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Resolving a complex ethical dilemma involving autonomous AI systems requires a structured approach that examines the nuances of ethical theories, stakeholder perspectives, and potential outcomes. Here's a step-by-step framework that can guide this process:\n",
      "\n",
      "### 1. Define the Ethical Dilemma\n",
      "Clearly articulate the specifics of the dilemma. Identify the competing values at play, such as the greater good versus individual rights, and outline the context in which the autonomous AI will operate.\n",
      "\n",
      "### 2. Identify Stakeholders\n",
      "Determine who is affected by the decision. This includes not only the users of the AI system but also individuals whose rights may be impacted, communities, and broader society. Understanding their perspectives is crucial.\n",
      "\n",
      "### 3. Gather Relevant Data\n",
      "Collect data on the implications of the AI's decisions. This includes empirical evidence about potential outcomes, historical precedents, and expert opinions. Understanding the technology's capabilities and limitations can also help inform the decision.\n",
      "\n",
      "### 4. Consider Ethical Frameworks\n",
      "Analyze the dilemma through different ethical lenses:\n",
      "- **Utilitarianism**: Evaluate how decisions affect the overall good and weigh the benefits against the harms.\n",
      "- **Deontological Ethics**: Consider duties and rights, emphasizing individual rights regardless of the outcomes.\n",
      "- **Virtue Ethics**: Reflect on the character and values that should guide decisions about the AI's actions.\n",
      "\n",
      "### 5. Assess the Potential for Unintended Consequences\n",
      "Conduct a thorough risk assessment to understand potential unintended consequences of the AI's actions. This involves scenario planning to consider various outcomes and their likelihood.\n",
      "\n",
      "### 6. Develop Guiding Principles\n",
      "Establish a set of ethical principles that will guide the design and deployment of the AI system. These principles should reflect a balance between the greater good and individual rights, transparency, accountability, and fairness.\n",
      "\n",
      "### 7. Create Feedback Mechanisms\n",
      "Implement systems for ongoing monitoring and evaluation of the AI's impact. This involves creating feedback loops with stakeholders to adapt and improve the system based on real-world outcomes.\n",
      "\n",
      "### 8. Engage Stakeholders in Dialogue\n",
      "Facilitate discussions with stakeholders to gather insights, address concerns, and refine the approach. This can help build trust and ensure that diverse perspectives inform the decision-making process.\n",
      "\n",
      "### 9. Explore Compromise Solutions\n",
      "Look for options that may satisfy both the prioritization of the greater good and the protection of individual rights. This could include limited opt-outs for individuals, layered decision-making processes, or tiered approaches based on risk assessment.\n",
      "\n",
      "### 10. Implement and Review\n",
      "After determining a course of action, implement it with transparency and accountability. Establish a clear review process to examine the outcomes and make necessary adjustments based on findings and stakeholder feedback.\n",
      "\n",
      "### 11. Stay Informed\n",
      "Stay abreast of developments in ethical standards, regulatory frameworks, and societal attitudes toward AI and its implications. Continuous education and adaptation are critical as technology evolves.\n",
      "\n",
      "### Conclusion\n",
      "Resolving ethical dilemmas in autonomous AI requires careful consideration of competing interests, ongoing stakeholder engagement, and a commitment to transparency and accountability. By following a structured approach, we can better navigate the complexities of these dilemmas while striving for equitable outcomes.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Resolving complex ethical dilemmas involving autonomous AI systems prioritizing the greater good, individual rights, and unintended consequences requires a multi-faceted approach that incorporates ethical frameworks, technical considerations, and stakeholder engagement. Here's a breakdown of how I would approach such a situation:\n",
      "\n",
      "**1. Defining the Ethical Dilemma and Scope:**\n",
      "\n",
      "*   **Clearly articulate the dilemma:** What specific scenario is causing the ethical conflict?  For example: \"Autonomous vehicles need to decide between swerving to avoid hitting a group of pedestrians and potentially injuring the car's occupants, or continuing straight, potentially causing more casualties.\"\n",
      "*   **Identify stakeholders:**  Who are all the parties affected by the AI's decisions? (Pedestrians, vehicle occupants, manufacturers, regulators, society as a whole, etc.)\n",
      "*   **Define the relevant values:**  What ethical values are in conflict? (Utilitarianism/Greatest Good vs. Individual Rights/Deontology vs. Justice/Fairness).  Specifically, consider:\n",
      "    *   **The \"greater good\":**  How is it being defined and measured? (e.g., minimizing fatalities, injuries, economic impact).  Who defines it?\n",
      "    *   **Individual rights:**  What rights are at stake? (e.g., right to life, bodily autonomy, due process).\n",
      "    *   **Unintended consequences:**  What potential long-term or unforeseen impacts could the AI's decisions have? (e.g., public trust in AI, discriminatory outcomes, economic disparities).\n",
      "*   **Establish boundaries:**  What are the legal, regulatory, and practical constraints that apply to the situation?\n",
      "\n",
      "**2. Ethical Frameworks and Principles:**\n",
      "\n",
      "*   **Apply relevant ethical theories:**\n",
      "    *   **Utilitarianism:**  Maximize overall well-being.  Weigh the potential outcomes and choose the action that benefits the most people.  Challenges:  Requires accurate prediction of consequences, can justify sacrificing individual rights for the sake of the majority, difficult to quantify happiness or well-being.\n",
      "    *   **Deontology (Duty-Based Ethics):**  Adhere to moral rules and duties, regardless of consequences.  For example, the AI might always prioritize preserving human life, even if it means sacrificing property. Challenges:  Rules can conflict, and it may be inflexible in complex situations.\n",
      "    *   **Virtue Ethics:**  Focus on cultivating virtuous character traits in the AI (or its creators), such as fairness, compassion, and justice.  Challenges:  Difficult to define and operationalize virtues in AI systems. Subjective to interpretation.\n",
      "    *   **Justice/Fairness:** Strive for equitable distribution of benefits and burdens. Avoid discrimination or bias in the AI's decision-making. Challenges:  Defining what constitutes \"fairness\" can be subjective and context-dependent.\n",
      "*   **Consider common principles in AI ethics:**\n",
      "    *   **Beneficence:**  The AI should aim to do good.\n",
      "    *   **Non-maleficence:**  The AI should avoid causing harm.\n",
      "    *   **Autonomy:**  Respect the autonomy of individuals (to the extent possible).\n",
      "    *   **Justice:**  Ensure fairness and avoid bias.\n",
      "    *   **Transparency:**  Make the AI's decision-making process understandable and explainable.\n",
      "    *   **Accountability:**  Establish mechanisms for holding the AI and its creators accountable for its actions.\n",
      "\n",
      "**3. Technical Considerations:**\n",
      "\n",
      "*   **Scenario Modeling and Simulation:**  Create realistic simulations of different scenarios to test the AI's decision-making under various conditions.  This can help identify potential unintended consequences and biases.\n",
      "*   **Algorithmic Transparency and Explainability (XAI):**  Design the AI so that its decision-making process is as transparent and understandable as possible. Use techniques like SHAP or LIME to explain why the AI made a particular decision.  This helps build trust and allows for auditing.\n",
      "*   **Bias Detection and Mitigation:**  Thoroughly analyze the data used to train the AI for potential biases.  Use techniques like re-weighting data or adversarial training to mitigate bias in the AI's decision-making.\n",
      "*   **Robustness and Error Handling:**  Ensure the AI is robust to noisy or incomplete data.  Develop mechanisms for detecting and handling errors.\n",
      "*   **Human Oversight and Intervention:**  Design the AI system to allow for human oversight and intervention in critical situations.  The level of human intervention should be carefully calibrated based on the risk and complexity of the situation.\n",
      "*   **Formal Verification:**  Where possible, use formal methods to verify that the AI's code and logic satisfy specific safety and ethical requirements.\n",
      "\n",
      "**4. Stakeholder Engagement:**\n",
      "\n",
      "*   **Involve a diverse range of stakeholders:**  Ethicists, legal experts, AI developers, policymakers, members of the public, and representatives from affected communities should all be involved in the decision-making process.\n",
      "*   **Solicit feedback and incorporate different perspectives:**  Conduct surveys, focus groups, and public forums to gather input on the ethical considerations and potential impacts of the AI system.\n",
      "*   **Establish clear communication channels:**  Keep stakeholders informed about the AI's development and deployment, and provide opportunities for them to raise concerns.\n",
      "\n",
      "**5. Iterative Development and Monitoring:**\n",
      "\n",
      "*   **Adopt an iterative development approach:**  Continuously evaluate and refine the AI's ethical decision-making based on feedback and new information.\n",
      "*   **Implement monitoring and auditing mechanisms:**  Regularly monitor the AI's performance to detect any unintended consequences or biases.  Conduct audits to ensure the AI is operating in accordance with ethical principles.\n",
      "*   **Establish a feedback loop:**  Use the data gathered from monitoring and auditing to improve the AI's design and training data.\n",
      "\n",
      "**6. Documentation and Justification:**\n",
      "\n",
      "*   **Document all ethical considerations and decisions:**  Maintain a detailed record of the ethical frameworks, principles, and stakeholder feedback that informed the AI's design.\n",
      "*   **Provide clear justifications for the AI's actions:**  Be able to explain why the AI made a particular decision in a given situation, and how that decision aligns with ethical principles.\n",
      "\n",
      "**Example Application to the Autonomous Vehicle Dilemma:**\n",
      "\n",
      "1.  **Dilemma:** Car faces the choice of swerving (potentially injuring passengers) or hitting pedestrians.\n",
      "2.  **Stakeholders:** Passengers, pedestrians, car manufacturer, regulators, society.\n",
      "3.  **Values in Conflict:** Passenger safety (individual right), pedestrian safety (individual right), minimizing total harm (greater good).\n",
      "4.  **Ethical Frameworks:**\n",
      "    *   *Utilitarianism*: May favor swerving to hit one person to save many, but raises moral issues.\n",
      "    *   *Deontology*:  Might prioritize any human life over property damage, but doesn't resolve trade-offs between lives.\n",
      "5.  **Technical:**\n",
      "    *   Simulate scenarios and train the AI on a vast dataset of accidents.\n",
      "    *   Implement sensor fusion and object detection to accurately identify pedestrians and obstacles.\n",
      "    *   Build-in explainability features to show why the car chose a specific action.\n",
      "6.  **Stakeholder Engagement:**\n",
      "    *   Survey public opinion on acceptable trade-offs.\n",
      "    *   Consult ethicists on the moral implications of different programming choices.\n",
      "7.  **Solution (Illustrative):**\n",
      "    *   Develop a tiered system:\n",
      "        *   *Level 1 (Emergency):* Unavoidable collision.  Prioritize minimizing overall fatalities, with slight bias towards protecting occupants due to the contract of transportation.\n",
      "        *   *Level 2 (Warning):*  Time to warn occupants and initiate controlled braking.\n",
      "        *   *Level 3 (Safe Zone):*  System drives within safety parameters to avoid emergency situations.\n",
      "    *   Implement robust data collection and monitoring to identify and address biases in the algorithm.\n",
      "\n",
      "**Key Considerations Throughout the Process:**\n",
      "\n",
      "*   **Context matters:** Ethical decisions are highly context-dependent. The AI's response should be tailored to the specific circumstances of the situation.\n",
      "*   **No perfect solution:** Ethical dilemmas often involve trade-offs, and there may be no perfect solution that satisfies all stakeholders.\n",
      "*   **Continuous learning:** The field of AI ethics is constantly evolving.  It's important to stay up-to-date on the latest research and best practices.\n",
      "\n",
      "By following this multi-faceted approach, we can strive to develop autonomous AI systems that are not only technically advanced but also ethically responsible.  The challenge lies in balancing the potential benefits of AI with the need to protect individual rights and prevent unintended consequences. The key is transparency, accountability, and continuous improvement.\n",
      "\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "What a fascinating and timely question! Resolving complex ethical dilemmas involving autonomous AI systems requires a multidisciplinary approach that incorporates philosophical, technical, social, and legal perspectives. Here's a step-by-step guide to help navigate this challenge:\n",
      "\n",
      "**1. Clarify the Dilemma**\n",
      "\n",
      "* Define the problem: clearly articulate the dilemma, including the context, relevant stakeholders, and conflicting values.\n",
      "* Identify key questions: what are the core concerns, and which rights or interests are in conflict?\n",
      "\n",
      "**2. Establish a Framework for Decision-Making**\n",
      "\n",
      "* Develop a decision-making framework that balances competing interests:\n",
      "\t+ Greater good vs. individual rights\n",
      "\t+ Human well-being vs. AI system goals\n",
      "\t+ Autonomy vs. accountability\n",
      "\t+ Transparency vs. complexity\n",
      "* Consider moral and philosophical theories, such as utilitarianism, deontology, or virtue ethics.\n",
      "\n",
      "**3. Evaluate the Autonomous AI System's Goals**\n",
      "\n",
      "* Understand the AI system's objectives, decision-making processes, and limitations:\n",
      "\t+ What is its primary goal (e.g., maximize efficiency, minimize harm)?\n",
      "\t+ How does it prioritize competing interests?\n",
      "\t+ Are there any built-in safeguards to prevent unintended consequences?\n",
      "\n",
      "**4. Consider Potential Unintended Consequences**\n",
      "\n",
      "* Anticipate potential outcomes of the autonomous AI system's actions:\n",
      "\t+ Short-term and long-term effects on individuals, groups, or society as a whole\n",
      "\t+ Possibility of unforeseen side effects or feedback loops\n",
      "\t+ Risks associated with over-reliance on AI decision-making\n",
      "\n",
      "**5. Involve Stakeholder Engagement**\n",
      "\n",
      "* Collaborate with diverse stakeholders to gather input and insights:\n",
      "\t+ Experts in relevant fields (e.g., ethics, law, philosophy, computer science)\n",
      "\t+ Representatives from affected groups or communities\n",
      "\t+ Decision-makers and policymakers\n",
      "* Consider using methods like Delphi technique, focus groups, or surveys to facilitate inclusive discussions.\n",
      "\n",
      "**6. Develop a Risk-Benefit Analysis**\n",
      "\n",
      "* Evaluate the potential benefits and risks of each possible course of action:\n",
      "\t+ Weigh the trade-offs between competing interests (e.g., individual rights vs. collective good)\n",
      "\t+ Consider multiple scenarios and outcomes\n",
      "\t+ Use decision-making tools like decision trees or game theory to facilitate analysis\n",
      "\n",
      "**7. Establish Clear Guidelines and Oversight**\n",
      "\n",
      "* Develop clear guidelines, regulations, or standards for autonomous AI systems:\n",
      "\t+ Define the roles and responsibilities of humans in AI decision-making processes\n",
      "\t+ Ensure transparency and accountability throughout the development and deployment process\n",
      "\t+ Establish mechanisms for ongoing evaluation and improvement\n",
      "\n",
      "**8. Monitor and Review Progress**\n",
      "\n",
      "* Continuously monitor the performance and impact of autonomous AI systems:\n",
      "\t+ Track outcomes, successes, and failures\n",
      "\t+ Conduct regular reviews to assess alignment with established guidelines and values\n",
      "\t+ Update decision-making frameworks as necessary\n",
      "\n",
      "**9. Address Uncertainty and Ambiguity**\n",
      "\n",
      "* Acknowledge that uncertainty and ambiguity are inherent in complex ethical dilemmas:\n",
      "\t+ Be prepared to adapt decision-making frameworks in response to new information or changing circumstances\n",
      "\t+ Encourage ongoing dialogue and education among stakeholders to improve understanding and address concerns.\n",
      "\n",
      "By following this structured approach, it's possible to navigate the complexities of resolving a dilemma involving autonomous AI systems prioritizing the greater good while considering individual rights and potential unintended consequences. However, remember that no single framework can fully capture the nuances of these issues; iterative refinement and ongoing collaboration will be essential for developing effective solutions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 3 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How would you approach resolving a complex ethical dilemma involving autonomous AI systems prioritizing the greater good, while also considering individual rights and the potential for unintended consequences?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Resolving a complex ethical dilemma involving autonomous AI systems requires a structured approach that examines the nuances of ethical theories, stakeholder perspectives, and potential outcomes. Here's a step-by-step framework that can guide this process:\n",
      "\n",
      "### 1. Define the Ethical Dilemma\n",
      "Clearly articulate the specifics of the dilemma. Identify the competing values at play, such as the greater good versus individual rights, and outline the context in which the autonomous AI will operate.\n",
      "\n",
      "### 2. Identify Stakeholders\n",
      "Determine who is affected by the decision. This includes not only the users of the AI system but also individuals whose rights may be impacted, communities, and broader society. Understanding their perspectives is crucial.\n",
      "\n",
      "### 3. Gather Relevant Data\n",
      "Collect data on the implications of the AI's decisions. This includes empirical evidence about potential outcomes, historical precedents, and expert opinions. Understanding the technology's capabilities and limitations can also help inform the decision.\n",
      "\n",
      "### 4. Consider Ethical Frameworks\n",
      "Analyze the dilemma through different ethical lenses:\n",
      "- **Utilitarianism**: Evaluate how decisions affect the overall good and weigh the benefits against the harms.\n",
      "- **Deontological Ethics**: Consider duties and rights, emphasizing individual rights regardless of the outcomes.\n",
      "- **Virtue Ethics**: Reflect on the character and values that should guide decisions about the AI's actions.\n",
      "\n",
      "### 5. Assess the Potential for Unintended Consequences\n",
      "Conduct a thorough risk assessment to understand potential unintended consequences of the AI's actions. This involves scenario planning to consider various outcomes and their likelihood.\n",
      "\n",
      "### 6. Develop Guiding Principles\n",
      "Establish a set of ethical principles that will guide the design and deployment of the AI system. These principles should reflect a balance between the greater good and individual rights, transparency, accountability, and fairness.\n",
      "\n",
      "### 7. Create Feedback Mechanisms\n",
      "Implement systems for ongoing monitoring and evaluation of the AI's impact. This involves creating feedback loops with stakeholders to adapt and improve the system based on real-world outcomes.\n",
      "\n",
      "### 8. Engage Stakeholders in Dialogue\n",
      "Facilitate discussions with stakeholders to gather insights, address concerns, and refine the approach. This can help build trust and ensure that diverse perspectives inform the decision-making process.\n",
      "\n",
      "### 9. Explore Compromise Solutions\n",
      "Look for options that may satisfy both the prioritization of the greater good and the protection of individual rights. This could include limited opt-outs for individuals, layered decision-making processes, or tiered approaches based on risk assessment.\n",
      "\n",
      "### 10. Implement and Review\n",
      "After determining a course of action, implement it with transparency and accountability. Establish a clear review process to examine the outcomes and make necessary adjustments based on findings and stakeholder feedback.\n",
      "\n",
      "### 11. Stay Informed\n",
      "Stay abreast of developments in ethical standards, regulatory frameworks, and societal attitudes toward AI and its implications. Continuous education and adaptation are critical as technology evolves.\n",
      "\n",
      "### Conclusion\n",
      "Resolving ethical dilemmas in autonomous AI requires careful consideration of competing interests, ongoing stakeholder engagement, and a commitment to transparency and accountability. By following a structured approach, we can better navigate the complexities of these dilemmas while striving for equitable outcomes.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Resolving complex ethical dilemmas involving autonomous AI systems prioritizing the greater good, individual rights, and unintended consequences requires a multi-faceted approach that incorporates ethical frameworks, technical considerations, and stakeholder engagement. Here's a breakdown of how I would approach such a situation:\n",
      "\n",
      "**1. Defining the Ethical Dilemma and Scope:**\n",
      "\n",
      "*   **Clearly articulate the dilemma:** What specific scenario is causing the ethical conflict?  For example: \"Autonomous vehicles need to decide between swerving to avoid hitting a group of pedestrians and potentially injuring the car's occupants, or continuing straight, potentially causing more casualties.\"\n",
      "*   **Identify stakeholders:**  Who are all the parties affected by the AI's decisions? (Pedestrians, vehicle occupants, manufacturers, regulators, society as a whole, etc.)\n",
      "*   **Define the relevant values:**  What ethical values are in conflict? (Utilitarianism/Greatest Good vs. Individual Rights/Deontology vs. Justice/Fairness).  Specifically, consider:\n",
      "    *   **The \"greater good\":**  How is it being defined and measured? (e.g., minimizing fatalities, injuries, economic impact).  Who defines it?\n",
      "    *   **Individual rights:**  What rights are at stake? (e.g., right to life, bodily autonomy, due process).\n",
      "    *   **Unintended consequences:**  What potential long-term or unforeseen impacts could the AI's decisions have? (e.g., public trust in AI, discriminatory outcomes, economic disparities).\n",
      "*   **Establish boundaries:**  What are the legal, regulatory, and practical constraints that apply to the situation?\n",
      "\n",
      "**2. Ethical Frameworks and Principles:**\n",
      "\n",
      "*   **Apply relevant ethical theories:**\n",
      "    *   **Utilitarianism:**  Maximize overall well-being.  Weigh the potential outcomes and choose the action that benefits the most people.  Challenges:  Requires accurate prediction of consequences, can justify sacrificing individual rights for the sake of the majority, difficult to quantify happiness or well-being.\n",
      "    *   **Deontology (Duty-Based Ethics):**  Adhere to moral rules and duties, regardless of consequences.  For example, the AI might always prioritize preserving human life, even if it means sacrificing property. Challenges:  Rules can conflict, and it may be inflexible in complex situations.\n",
      "    *   **Virtue Ethics:**  Focus on cultivating virtuous character traits in the AI (or its creators), such as fairness, compassion, and justice.  Challenges:  Difficult to define and operationalize virtues in AI systems. Subjective to interpretation.\n",
      "    *   **Justice/Fairness:** Strive for equitable distribution of benefits and burdens. Avoid discrimination or bias in the AI's decision-making. Challenges:  Defining what constitutes \"fairness\" can be subjective and context-dependent.\n",
      "*   **Consider common principles in AI ethics:**\n",
      "    *   **Beneficence:**  The AI should aim to do good.\n",
      "    *   **Non-maleficence:**  The AI should avoid causing harm.\n",
      "    *   **Autonomy:**  Respect the autonomy of individuals (to the extent possible).\n",
      "    *   **Justice:**  Ensure fairness and avoid bias.\n",
      "    *   **Transparency:**  Make the AI's decision-making process understandable and explainable.\n",
      "    *   **Accountability:**  Establish mechanisms for holding the AI and its creators accountable for its actions.\n",
      "\n",
      "**3. Technical Considerations:**\n",
      "\n",
      "*   **Scenario Modeling and Simulation:**  Create realistic simulations of different scenarios to test the AI's decision-making under various conditions.  This can help identify potential unintended consequences and biases.\n",
      "*   **Algorithmic Transparency and Explainability (XAI):**  Design the AI so that its decision-making process is as transparent and understandable as possible. Use techniques like SHAP or LIME to explain why the AI made a particular decision.  This helps build trust and allows for auditing.\n",
      "*   **Bias Detection and Mitigation:**  Thoroughly analyze the data used to train the AI for potential biases.  Use techniques like re-weighting data or adversarial training to mitigate bias in the AI's decision-making.\n",
      "*   **Robustness and Error Handling:**  Ensure the AI is robust to noisy or incomplete data.  Develop mechanisms for detecting and handling errors.\n",
      "*   **Human Oversight and Intervention:**  Design the AI system to allow for human oversight and intervention in critical situations.  The level of human intervention should be carefully calibrated based on the risk and complexity of the situation.\n",
      "*   **Formal Verification:**  Where possible, use formal methods to verify that the AI's code and logic satisfy specific safety and ethical requirements.\n",
      "\n",
      "**4. Stakeholder Engagement:**\n",
      "\n",
      "*   **Involve a diverse range of stakeholders:**  Ethicists, legal experts, AI developers, policymakers, members of the public, and representatives from affected communities should all be involved in the decision-making process.\n",
      "*   **Solicit feedback and incorporate different perspectives:**  Conduct surveys, focus groups, and public forums to gather input on the ethical considerations and potential impacts of the AI system.\n",
      "*   **Establish clear communication channels:**  Keep stakeholders informed about the AI's development and deployment, and provide opportunities for them to raise concerns.\n",
      "\n",
      "**5. Iterative Development and Monitoring:**\n",
      "\n",
      "*   **Adopt an iterative development approach:**  Continuously evaluate and refine the AI's ethical decision-making based on feedback and new information.\n",
      "*   **Implement monitoring and auditing mechanisms:**  Regularly monitor the AI's performance to detect any unintended consequences or biases.  Conduct audits to ensure the AI is operating in accordance with ethical principles.\n",
      "*   **Establish a feedback loop:**  Use the data gathered from monitoring and auditing to improve the AI's design and training data.\n",
      "\n",
      "**6. Documentation and Justification:**\n",
      "\n",
      "*   **Document all ethical considerations and decisions:**  Maintain a detailed record of the ethical frameworks, principles, and stakeholder feedback that informed the AI's design.\n",
      "*   **Provide clear justifications for the AI's actions:**  Be able to explain why the AI made a particular decision in a given situation, and how that decision aligns with ethical principles.\n",
      "\n",
      "**Example Application to the Autonomous Vehicle Dilemma:**\n",
      "\n",
      "1.  **Dilemma:** Car faces the choice of swerving (potentially injuring passengers) or hitting pedestrians.\n",
      "2.  **Stakeholders:** Passengers, pedestrians, car manufacturer, regulators, society.\n",
      "3.  **Values in Conflict:** Passenger safety (individual right), pedestrian safety (individual right), minimizing total harm (greater good).\n",
      "4.  **Ethical Frameworks:**\n",
      "    *   *Utilitarianism*: May favor swerving to hit one person to save many, but raises moral issues.\n",
      "    *   *Deontology*:  Might prioritize any human life over property damage, but doesn't resolve trade-offs between lives.\n",
      "5.  **Technical:**\n",
      "    *   Simulate scenarios and train the AI on a vast dataset of accidents.\n",
      "    *   Implement sensor fusion and object detection to accurately identify pedestrians and obstacles.\n",
      "    *   Build-in explainability features to show why the car chose a specific action.\n",
      "6.  **Stakeholder Engagement:**\n",
      "    *   Survey public opinion on acceptable trade-offs.\n",
      "    *   Consult ethicists on the moral implications of different programming choices.\n",
      "7.  **Solution (Illustrative):**\n",
      "    *   Develop a tiered system:\n",
      "        *   *Level 1 (Emergency):* Unavoidable collision.  Prioritize minimizing overall fatalities, with slight bias towards protecting occupants due to the contract of transportation.\n",
      "        *   *Level 2 (Warning):*  Time to warn occupants and initiate controlled braking.\n",
      "        *   *Level 3 (Safe Zone):*  System drives within safety parameters to avoid emergency situations.\n",
      "    *   Implement robust data collection and monitoring to identify and address biases in the algorithm.\n",
      "\n",
      "**Key Considerations Throughout the Process:**\n",
      "\n",
      "*   **Context matters:** Ethical decisions are highly context-dependent. The AI's response should be tailored to the specific circumstances of the situation.\n",
      "*   **No perfect solution:** Ethical dilemmas often involve trade-offs, and there may be no perfect solution that satisfies all stakeholders.\n",
      "*   **Continuous learning:** The field of AI ethics is constantly evolving.  It's important to stay up-to-date on the latest research and best practices.\n",
      "\n",
      "By following this multi-faceted approach, we can strive to develop autonomous AI systems that are not only technically advanced but also ethically responsible.  The challenge lies in balancing the potential benefits of AI with the need to protect individual rights and prevent unintended consequences. The key is transparency, accountability, and continuous improvement.\n",
      "\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "What a fascinating and timely question! Resolving complex ethical dilemmas involving autonomous AI systems requires a multidisciplinary approach that incorporates philosophical, technical, social, and legal perspectives. Here's a step-by-step guide to help navigate this challenge:\n",
      "\n",
      "**1. Clarify the Dilemma**\n",
      "\n",
      "* Define the problem: clearly articulate the dilemma, including the context, relevant stakeholders, and conflicting values.\n",
      "* Identify key questions: what are the core concerns, and which rights or interests are in conflict?\n",
      "\n",
      "**2. Establish a Framework for Decision-Making**\n",
      "\n",
      "* Develop a decision-making framework that balances competing interests:\n",
      "\t+ Greater good vs. individual rights\n",
      "\t+ Human well-being vs. AI system goals\n",
      "\t+ Autonomy vs. accountability\n",
      "\t+ Transparency vs. complexity\n",
      "* Consider moral and philosophical theories, such as utilitarianism, deontology, or virtue ethics.\n",
      "\n",
      "**3. Evaluate the Autonomous AI System's Goals**\n",
      "\n",
      "* Understand the AI system's objectives, decision-making processes, and limitations:\n",
      "\t+ What is its primary goal (e.g., maximize efficiency, minimize harm)?\n",
      "\t+ How does it prioritize competing interests?\n",
      "\t+ Are there any built-in safeguards to prevent unintended consequences?\n",
      "\n",
      "**4. Consider Potential Unintended Consequences**\n",
      "\n",
      "* Anticipate potential outcomes of the autonomous AI system's actions:\n",
      "\t+ Short-term and long-term effects on individuals, groups, or society as a whole\n",
      "\t+ Possibility of unforeseen side effects or feedback loops\n",
      "\t+ Risks associated with over-reliance on AI decision-making\n",
      "\n",
      "**5. Involve Stakeholder Engagement**\n",
      "\n",
      "* Collaborate with diverse stakeholders to gather input and insights:\n",
      "\t+ Experts in relevant fields (e.g., ethics, law, philosophy, computer science)\n",
      "\t+ Representatives from affected groups or communities\n",
      "\t+ Decision-makers and policymakers\n",
      "* Consider using methods like Delphi technique, focus groups, or surveys to facilitate inclusive discussions.\n",
      "\n",
      "**6. Develop a Risk-Benefit Analysis**\n",
      "\n",
      "* Evaluate the potential benefits and risks of each possible course of action:\n",
      "\t+ Weigh the trade-offs between competing interests (e.g., individual rights vs. collective good)\n",
      "\t+ Consider multiple scenarios and outcomes\n",
      "\t+ Use decision-making tools like decision trees or game theory to facilitate analysis\n",
      "\n",
      "**7. Establish Clear Guidelines and Oversight**\n",
      "\n",
      "* Develop clear guidelines, regulations, or standards for autonomous AI systems:\n",
      "\t+ Define the roles and responsibilities of humans in AI decision-making processes\n",
      "\t+ Ensure transparency and accountability throughout the development and deployment process\n",
      "\t+ Establish mechanisms for ongoing evaluation and improvement\n",
      "\n",
      "**8. Monitor and Review Progress**\n",
      "\n",
      "* Continuously monitor the performance and impact of autonomous AI systems:\n",
      "\t+ Track outcomes, successes, and failures\n",
      "\t+ Conduct regular reviews to assess alignment with established guidelines and values\n",
      "\t+ Update decision-making frameworks as necessary\n",
      "\n",
      "**9. Address Uncertainty and Ambiguity**\n",
      "\n",
      "* Acknowledge that uncertainty and ambiguity are inherent in complex ethical dilemmas:\n",
      "\t+ Be prepared to adapt decision-making frameworks in response to new information or changing circumstances\n",
      "\t+ Encourage ongoing dialogue and education among stakeholders to improve understanding and address concerns.\n",
      "\n",
      "By following this structured approach, it's possible to navigate the complexities of resolving a dilemma involving autonomous AI systems prioritizing the greater good while considering individual rights and potential unintended consequences. However, remember that no single framework can fully capture the nuances of these issues; iterative refinement and ongoing collaboration will be essential for developing effective solutions.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"2\", \"1\", \"3\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: gpt-4o-mini\n",
      "Rank 3: llama3.1\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            and common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
